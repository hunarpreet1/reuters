{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "def read(dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels.idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels.idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError, \"dataset must be 'testing' or 'training'\"\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "        \n",
    "    return img,lbl\n",
    "\n",
    "#     get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "#     # Create an iterator which returns each image in turn\n",
    "#     for i in xrange(len(lbl)):\n",
    "#         yield get_img(i)\n",
    "\n",
    "def show(image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    from matplotlib import pyplot\n",
    "    import matplotlib as mpl\n",
    "    fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device to node 'MatMul_14': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: MatMul_14 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_14, b_14)]]\n\nCaused by op u'MatMul_14', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-a176f6aecf2f>\", line 5, in <module>\n    c = tf.matmul(a, b)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1801, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1263, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'MatMul_14': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: MatMul_14 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_14, b_14)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a176f6aecf2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Runs the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'MatMul_14': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: MatMul_14 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_14, b_14)]]\n\nCaused by op u'MatMul_14', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-a176f6aecf2f>\", line 5, in <module>\n    c = tf.matmul(a, b)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1801, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1263, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'MatMul_14': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: MatMul_14 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_14, b_14)]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "with tf.device('/gpu:0'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "  c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset,train_labels = read(dataset = \"training\", path = \".\")\n",
    "test_dataset,test_labels = read(dataset = \"testing\", path = \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADdlJREFUeJzt3X+MVfWZx/HPY3dEFGOgDITYwWmRkDQ14npjNoKNa7ON\nkhDB+GNJJGjM0mgnrrF/VN1EDH/Jplg02ZDAisVGrU3UwB+krUs02KikdwwLI5SKBKNkHIbQiFXU\nBZ794x6aKZ3zvZf745w7Pu9XMplzz3POPY9n/HB+3nPN3QUgnvPKbgBAOQg/EBThB4Ii/EBQhB8I\nivADQZUSfjO70cz2m9kBM3uojB7ymNkhM9tjZrvMrFpyL5vM7IiZDY0ZN83MXjWz97LfU7uot8fM\n7HC27naZ2aKSeuszs9fMbK+ZvWtm/56NL3XdJfoqZb1Z0df5zewbkv4k6V8kfSTpD5KWufveQhvJ\nYWaHJFXc/WgX9PJ9SX+R9Ky7fy8b95+Sjrn749k/nFPd/add0ttjkv7i7j8rup+zepslaZa7v2Nm\nF0salLRE0l0qcd0l+rpdJay3Mrb810g64O4H3f0rSb+SdHMJfXQ9d98h6dhZo2+WtDkb3qza/zyF\ny+mtK7j7sLu/kw1/KmmfpEtV8rpL9FWKMsJ/qaQPx7z+SCWugHG4pN+Z2aCZrSy7mXHMdPfhbPhj\nSTPLbGYcA2a2OzssKOWQZCwz65d0laSd6qJ1d1ZfUgnrjRN+f2+hu/+jpJsk/Tjbve1KXjtm66b7\ns9dLmiNpvqRhSWvLbMbMpkh6SdID7n58bK3MdTdOX6WstzLCf1hS35jX38rGdQV3P5z9PiLpFdUO\nU7rJSHbseOYY8kjJ/fyVu4+4+yl3Py1po0pcd2bWo1rAnnP3l7PRpa+78foqa72VEf4/SJprZt82\ns/Ml/aukrSX08XfM7KLsRIzM7CJJP5Q0lJ6rcFslrciGV0jaUmIvf+NMsDJLVdK6MzOT9LSkfe7+\nxJhSqesur6/S1pu7F/4jaZFqZ/zfl/QfZfSQ09d3JP1v9vNu2b1JekG13cD/U+3cyD2Svilpu6T3\nJP2PpGld1NsvJe2RtFu1oM0qqbeFqu3S75a0K/tZVPa6S/RVynor/FIfgO7ACT8gKMIPBEX4gaAI\nPxAU4QeCKjX8XXr7rKTu7a1b+5LorVll9Vb2lr9r/yDq3t66tS+J3poVMvwAStLSTT5mdqOkJyV9\nQ9J/u/vjqemnT5/u/f39f309Ojqq3t7eppffSd3aW7f2JdFbs9rZ26FDh3T06FFrZNp/aHYh2UM5\n/ktjHsphZls98VCO/v5+VaulPhwH+FqrVCoNT9vKbj8P5QAmsFbC3+0P5QCQ0PETfma20syqZlYd\nHR3t9OIANKiV8Df0UA533+DuFXevdOsJFyCiVsLftQ/lAFBf02f73f2kmQ1I+q1ql/o2ufu7besM\nQEc1HX5Jcvdtkra1qRcABeIOPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGg\nCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiB\noAg/EBThB4Jq6Vt6UYwvvvgiWd+2Lf+LkgcGBpLzjoyMJOunT59O1pcvX56sL1u2LLd20003JedF\nZ7UUfjM7JOlTSacknXT3SjuaAtB57djy/7O7H23D+wAoEMf8QFCtht8l/c7MBs1sZTsaAlCMVnf7\nF7r7YTObIelVM/uju+8YO0H2j8JKSZo9e3aLiwPQLi1t+d39cPb7iKRXJF0zzjQb3L3i7pXe3t5W\nFgegjZoOv5ldZGYXnxmW9ENJQ+1qDEBntbLbP1PSK2Z25n2ed/fftKWrYI4dO5asX3fddcn6/v37\nm1529vfLdd556e3D888/n6y/8cYbubUdO3bk1iSpr68vWUdrmg6/ux+UdGUbewFQIC71AUERfiAo\nwg8ERfiBoAg/EBQf6S3AW2+9lazfddddyfr777+frM+YMSO3dv/99yfnXbx4cbJ+4sSJZP22225L\n1j/88MPc2rp165Lzrl27NllHa9jyA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQXOcvwMGDB5P1AwcO\nJOv1HoLy2muv5dbmzZuXnLdVS5cuTdafeuqpji4fzWPLDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANB\ncZ2/APU+8/7JJ58k63fffXeyPnny5HPuqVGfffZZsr5x48am33vBggVNz4vWseUHgiL8QFCEHwiK\n8ANBEX4gKMIPBEX4gaC4zl+A888/P1m/7777Curk3NX7zoHPP/88Wb/jjjtya7fccktTPaE96m75\nzWyTmR0xs6Ex46aZ2atm9l72e2pn2wTQbo3s9v9C0o1njXtI0nZ3nytpe/YawARSN/zuvkPSsbNG\n3yxpcza8WdKSNvcFoMOaPeE3092Hs+GPJc3Mm9DMVppZ1cyqo6OjTS4OQLu1fLbf3V2SJ+ob3L3i\n7pV6D6IEUJxmwz9iZrMkKft9pH0tAShCs+HfKmlFNrxC0pb2tAOgKHWv85vZC5KulzTdzD6StErS\n45J+bWb3SPpA0u2dbBLNO3r0aLI+ODiYrC9atChZv/DCC5P1es8iQHnqht/dl+WUftDmXgAUiNt7\ngaAIPxAU4QeCIvxAUIQfCIqP9E4AX375ZbK+evXq3Nr69euT8x4/frypns7o6elJ1k+ePJlbq/ff\nNWnSpKZ6QmPY8gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUFznnwBef/31ZH3NmjXFNDKOevcJLF68\nOLd2xRVXJOd98803k/VOfjV5BGz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAorvNPANdee22yPnfu\n3NzaJZdckpz31ltvTdbvvffeZP3tt99O1gcGBnJre/bsSc77zDPPJOvd/NXmEwFbfiAowg8ERfiB\noAg/EBThB4Ii/EBQhB8Iyty9sIVVKhWvVquFLQ/lGxoayq1deeWVLb333r17k/V58+a19P4TUaVS\nUbVatUamrbvlN7NNZnbEzIbGjHvMzA6b2a7sJ/0l7gC6TiO7/b+QdOM443/u7vOzn23tbQtAp9UN\nv7vvkHSsgF4AFKiVE34DZrY7OyyYmjeRma00s6qZVUdHR1tYHIB2ajb86yXNkTRf0rCktXkTuvsG\nd6+4e6W3t7fJxQFot6bC7+4j7n7K3U9L2ijpmva2BaDTmgq/mc0a83KppPzrOQC6Ut3P85vZC5Ku\nlzTdzD6StErS9WY2X5JLOiTpRx3sERNYf39/bm3OnDnJeQ8ePJis17tnJOJ1/nNRN/zuvmyc0U93\noBcABeL2XiAowg8ERfiBoAg/EBThB4Li0d3oqClTpuTWZsyYkZy33qU+tIYtPxAU4QeCIvxAUIQf\nCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTF5/nRUfv378+tDQ4OFtgJ\nzsaWHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCauQruvskPStppmpfyb3B3Z80s2mSXpTUr9rXdN/u\n7n/uXKvoRqdOnUrWt27dmlv76quvWlr2woULW5o/uka2/Ccl/cTdvyvpnyT92My+K+khSdvdfa6k\n7dlrABNE3fC7+7C7v5MNfyppn6RLJd0saXM22WZJSzrVJID2O6djfjPrl3SVpJ2SZrr7cFb6WLXD\nAgATRMPhN7Mpkl6S9IC7Hx9bc3dX7XzAePOtNLOqmVVHR0dbahZA+zQUfjPrUS34z7n7y9noETOb\nldVnSToy3rzuvsHdK+5e6e3tbUfPANqgbvjNzCQ9LWmfuz8xprRV0opseIWkLe1vD0CnNPKR3gWS\nlkvaY2a7snGPSHpc0q/N7B5JH0i6vTMtfv3Vu1w2MjKSrE+ePDm3NnXq1KZ6OqNeb+vWrUvWH374\n4dxabbuS78EHH0zWL7vssmQdaXXD7+6/l5T3V/pBe9sBUBTu8AOCIvxAUIQfCIrwA0ERfiAowg8E\nxaO7u8CJEyeS9dmzZyfrqTsnX3zxxeS806ZNS9ZXrVqVrG/Z0vy9XX19fcn66tWrm35v1MeWHwiK\n8ANBEX4gKMIPBEX4gaAIPxAU4QeC4jr/10Dq8Wg33HBDS+9de0JbvnpPZ3r00Udza3feeWdy3gsu\nuCBZR2vY8gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUFzn7wI9PT3J+tVXX52sDw4OtrOdv7FmzZpk\nfcmS9PezXn755e1sB23Elh8IivADQRF+ICjCDwRF+IGgCD8QFOEHgqp7nd/M+iQ9K2mmJJe0wd2f\nNLPHJP2bpDMfJn/E3bd1qtGvs0mTJiXrO3fuLKgTRNLITT4nJf3E3d8xs4slDZrZq1nt5+7+s861\nB6BT6obf3YclDWfDn5rZPkmXdroxAJ11Tsf8ZtYv6SpJZ/ZDB8xst5ltMrOpbe4NQAc1HH4zmyLp\nJUkPuPtxSeslzZE0X7U9g7U58600s6qZVVPPmgNQrIbCb2Y9qgX/OXd/WZLcfcTdT7n7aUkbJV0z\n3rzuvsHdK+5eqfewRwDFqRt+MzNJT0va5+5PjBk/a8xkSyUNtb89AJ3SyNn+BZKWS9pjZruycY9I\nWmZm81W7/HdI0o860iGAjmjkbP/vJdk4Ja7pAxMYd/gBQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCE\nHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCMncvbmFmo5I+KGyBQDyXuXtDj8wqNPwAuge7/UBQhB8I\nivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFD/D182KNLxxBitAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f997499aa50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(train_dataset[98])\n",
    "\n",
    "[random.randint(14,50) for x in range(2)]\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#choose a more apt argument for randint\n",
    "def randCentre():\n",
    "    image1_centre = [32,random.randint(14,23)]\n",
    "    image2_centre = [32,random.randint(40,49)]\n",
    "    return image1_centre,image2_centre\n",
    "\n",
    "def randIndex():\n",
    "    image1_index = random.randint(0,1000)\n",
    "    image2_index = random.randint(0,1000)\n",
    "    return image1_index,image2_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainingSet1 (train_dataset,train_labels):\n",
    "    train_dataset_2digit = np.zeros((1000,64,64))\n",
    "    train_dataset_2digit_labels = np.zeros((1000))\n",
    "    for count in range(1000):\n",
    "        image1_index,image2_index = randIndex()\n",
    "        image1_centre,image2_centre = randCentre()\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                train_dataset_2digit[count][image1_centre[0] - 14 + i][image1_centre[1] - 14 + j] = (train_dataset[image1_index][i][j]-128)/128\n",
    "                train_dataset_2digit[count][image2_centre[0] - 14 + i][image2_centre[1] - 14 + j] = (train_dataset[image2_index][i][j]-128)/128\n",
    "        if(image1_centre[1]>image2_centre[1]): train_dataset_2digit_labels[count] = 10*train_labels[image2_index]+train_labels[image1_index]\n",
    "        else: train_dataset_2digit_labels[count] = 10*train_labels[image1_index]+train_labels[image2_index]\n",
    "    \n",
    "    return train_dataset_2digit,train_dataset_2digit_labels    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = trainingSet1(train_dataset,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset1,test_labels1 = trainingSet1(test_dataset,test_labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge(array1,array2):\n",
    "    array = np.concatenate((array1, array2), axis=0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permute(array):\n",
    "    return np.random.permutation(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 97.  38.  49. ...,  36.  51.   4.]\n"
     ]
    }
   ],
   "source": [
    "train_dataset1 = x\n",
    "train_labels1 = y\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset1 = (train_dataset1 - 128)/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (100000, 64, 64, 1), (100000, 100))\n",
      "('Test set', (1000, 64, 64, 1), (1000, 100))\n"
     ]
    }
   ],
   "source": [
    "image_size = 64\n",
    "num_labels = 100\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset1, train_labels1 = reformat(train_dataset1, train_labels1)\n",
    "test_dataset1, test_labels1 = reformat(test_dataset1, test_labels1)\n",
    "print('Training set', train_dataset1.shape, train_labels1.shape)\n",
    "print('Test set', test_dataset1.shape, test_labels1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQQ6+WYL+HwbdTNGuvXzQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f99725a8450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(x[3])\n",
    "train_labels1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "patch_size = 5\n",
    "depth = 64\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_test_dataset = tf.constant(test_dataset1,dtype=tf.float32)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  global_step = tf.Variable(0)  \n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "  learning_rate = tf.train.exponential_decay(0.05, global_step, 1000, 0.85, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 7.205978\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 50: 4.621195\n",
      "Minibatch accuracy: 0.0%\n",
      "Minibatch loss at step 100: 4.575899\n",
      "Minibatch accuracy: 0.8%\n",
      "Minibatch loss at step 150: 4.601332\n",
      "Minibatch accuracy: 1.6%\n",
      "Minibatch loss at step 200: 4.531965\n",
      "Minibatch accuracy: 2.3%\n",
      "Minibatch loss at step 250: 4.429788\n",
      "Minibatch accuracy: 3.9%\n",
      "Minibatch loss at step 300: 4.258839\n",
      "Minibatch accuracy: 4.7%\n",
      "Minibatch loss at step 350: 3.954561\n",
      "Minibatch accuracy: 7.0%\n",
      "Minibatch loss at step 400: 3.259746\n",
      "Minibatch accuracy: 16.4%\n",
      "Minibatch loss at step 450: 2.974470\n",
      "Minibatch accuracy: 18.0%\n",
      "Minibatch loss at step 500: 2.578224\n",
      "Minibatch accuracy: 25.8%\n",
      "Minibatch loss at step 550: 2.203219\n",
      "Minibatch accuracy: 34.4%\n",
      "Minibatch loss at step 600: 2.392950\n",
      "Minibatch accuracy: 38.3%\n",
      "Minibatch loss at step 650: 2.013759\n",
      "Minibatch accuracy: 41.4%\n",
      "Minibatch loss at step 700: 1.746876\n",
      "Minibatch accuracy: 51.6%\n",
      "Minibatch loss at step 750: 1.924506\n",
      "Minibatch accuracy: 44.5%\n",
      "Minibatch loss at step 800: 1.876078\n",
      "Minibatch accuracy: 53.1%\n",
      "Minibatch loss at step 850: 1.266162\n",
      "Minibatch accuracy: 63.3%\n",
      "Minibatch loss at step 900: 1.505663\n",
      "Minibatch accuracy: 49.2%\n",
      "Minibatch loss at step 950: 1.176972\n",
      "Minibatch accuracy: 65.6%\n",
      "Minibatch loss at step 1000: 1.284605\n",
      "Minibatch accuracy: 58.6%\n",
      "Minibatch loss at step 1050: 1.075997\n",
      "Minibatch accuracy: 68.0%\n",
      "Minibatch loss at step 1100: 1.159559\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 1150: 1.061553\n",
      "Minibatch accuracy: 68.8%\n",
      "Minibatch loss at step 1200: 0.899556\n",
      "Minibatch accuracy: 74.2%\n",
      "Minibatch loss at step 1250: 0.894119\n",
      "Minibatch accuracy: 78.9%\n",
      "Minibatch loss at step 1300: 0.856242\n",
      "Minibatch accuracy: 81.2%\n",
      "Minibatch loss at step 1350: 0.895854\n",
      "Minibatch accuracy: 76.6%\n",
      "Minibatch loss at step 1400: 0.770788\n",
      "Minibatch accuracy: 75.8%\n",
      "Minibatch loss at step 1450: 0.513265\n",
      "Minibatch accuracy: 84.4%\n",
      "Minibatch loss at step 1500: 0.757289\n",
      "Minibatch accuracy: 77.3%\n",
      "Minibatch loss at step 1550: 0.766059\n",
      "Minibatch accuracy: 78.9%\n",
      "Minibatch loss at step 1600: 0.585638\n",
      "Minibatch accuracy: 82.8%\n",
      "Minibatch loss at step 1650: 0.577001\n",
      "Minibatch accuracy: 83.6%\n",
      "Minibatch loss at step 1700: 0.589864\n",
      "Minibatch accuracy: 82.0%\n",
      "Minibatch loss at step 1750: 0.863727\n",
      "Minibatch accuracy: 73.4%\n",
      "Minibatch loss at step 1800: 0.484519\n",
      "Minibatch accuracy: 84.4%\n",
      "Minibatch loss at step 1850: 0.561912\n",
      "Minibatch accuracy: 82.8%\n",
      "Minibatch loss at step 1900: 0.531341\n",
      "Minibatch accuracy: 82.0%\n",
      "Minibatch loss at step 1950: 0.602899\n",
      "Minibatch accuracy: 82.8%\n",
      "Minibatch loss at step 2000: 0.448137\n",
      "Minibatch accuracy: 83.6%\n",
      "Minibatch loss at step 2050: 0.409228\n",
      "Minibatch accuracy: 88.3%\n",
      "Minibatch loss at step 2100: 0.491276\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 2150: 0.732805\n",
      "Minibatch accuracy: 79.7%\n",
      "Minibatch loss at step 2200: 0.643476\n",
      "Minibatch accuracy: 80.5%\n",
      "Minibatch loss at step 2250: 0.503035\n",
      "Minibatch accuracy: 85.2%\n",
      "Minibatch loss at step 2300: 0.441235\n",
      "Minibatch accuracy: 88.3%\n",
      "Minibatch loss at step 2350: 0.530594\n",
      "Minibatch accuracy: 78.9%\n",
      "Minibatch loss at step 2400: 0.418608\n",
      "Minibatch accuracy: 88.3%\n",
      "Minibatch loss at step 2450: 0.463655\n",
      "Minibatch accuracy: 85.9%\n",
      "Minibatch loss at step 2500: 0.372844\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 2550: 0.415989\n",
      "Minibatch accuracy: 86.7%\n",
      "Minibatch loss at step 2600: 0.370851\n",
      "Minibatch accuracy: 90.6%\n",
      "Minibatch loss at step 2650: 0.408545\n",
      "Minibatch accuracy: 86.7%\n",
      "Minibatch loss at step 2700: 0.236934\n",
      "Minibatch accuracy: 89.8%\n",
      "Minibatch loss at step 2750: 0.420498\n",
      "Minibatch accuracy: 89.1%\n",
      "Minibatch loss at step 2800: 0.419671\n",
      "Minibatch accuracy: 82.8%\n",
      "Minibatch loss at step 2850: 0.297838\n",
      "Minibatch accuracy: 92.2%\n",
      "Minibatch loss at step 2900: 0.375431\n",
      "Minibatch accuracy: 87.5%\n",
      "Minibatch loss at step 2950: 0.319021\n",
      "Minibatch accuracy: 92.2%\n",
      "Test accuracy: 87.3%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels1.shape[0] - batch_size)\n",
    "    batch_data = train_dataset1[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels1[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      #print('Validation accuracy: %.1f%%' % accuracy(\n",
    "       # valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "128\n",
      "256\n",
      "384\n",
      "512\n",
      "640\n",
      "768\n",
      "896\n",
      "1024\n",
      "1152\n",
      "1280\n",
      "1408\n",
      "1536\n",
      "1664\n",
      "1792\n",
      "1920\n",
      "2048\n",
      "2176\n",
      "2304\n",
      "2432\n",
      "2560\n",
      "2688\n",
      "2816\n",
      "2944\n",
      "3072\n",
      "3200\n",
      "3328\n",
      "3456\n",
      "3584\n",
      "3712\n",
      "3840\n",
      "3968\n",
      "4096\n",
      "4224\n",
      "4352\n",
      "4480\n",
      "4608\n",
      "4736\n",
      "4864\n",
      "4992\n",
      "5120\n",
      "5248\n",
      "5376\n",
      "5504\n",
      "5632\n",
      "5760\n",
      "5888\n",
      "6016\n",
      "6144\n",
      "6272\n",
      "6400\n",
      "6528\n",
      "6656\n",
      "6784\n",
      "6912\n",
      "7040\n",
      "7168\n",
      "7296\n",
      "7424\n",
      "7552\n",
      "7680\n",
      "7808\n",
      "7936\n",
      "8064\n",
      "8192\n",
      "8320\n",
      "8448\n",
      "8576\n",
      "8704\n",
      "8832\n",
      "8960\n",
      "9088\n",
      "9216\n",
      "9344\n",
      "9472\n",
      "9600\n",
      "9728\n",
      "9856\n",
      "9984\n",
      "10112\n",
      "10240\n",
      "10368\n",
      "10496\n",
      "10624\n",
      "10752\n",
      "10880\n",
      "11008\n",
      "11136\n",
      "11264\n",
      "11392\n",
      "11520\n",
      "11648\n",
      "11776\n",
      "11904\n",
      "12032\n",
      "12160\n",
      "12288\n",
      "12416\n",
      "12544\n",
      "12672\n",
      "12800\n",
      "12928\n",
      "13056\n",
      "13184\n",
      "13312\n",
      "13440\n",
      "13568\n",
      "13696\n",
      "13824\n",
      "13952\n",
      "14080\n",
      "14208\n",
      "14336\n",
      "14464\n",
      "14592\n",
      "14720\n",
      "14848\n",
      "14976\n",
      "15104\n",
      "15232\n",
      "15360\n",
      "15488\n",
      "15616\n",
      "15744\n",
      "15872\n",
      "16000\n",
      "16128\n",
      "16256\n",
      "16384\n",
      "16512\n",
      "16640\n",
      "16768\n",
      "16896\n",
      "17024\n",
      "17152\n",
      "17280\n",
      "17408\n",
      "17536\n",
      "17664\n",
      "17792\n",
      "17920\n",
      "18048\n",
      "18176\n",
      "18304\n",
      "18432\n",
      "18560\n",
      "18688\n",
      "18816\n",
      "18944\n",
      "19072\n",
      "19200\n",
      "19328\n",
      "19456\n",
      "19584\n",
      "19712\n",
      "19840\n",
      "19968\n",
      "20096\n",
      "20224\n",
      "20352\n",
      "20480\n",
      "20608\n",
      "20736\n",
      "20864\n",
      "20992\n",
      "21120\n",
      "21248\n",
      "21376\n",
      "21504\n",
      "21632\n",
      "21760\n",
      "21888\n",
      "22016\n",
      "22144\n",
      "22272\n",
      "22400\n",
      "22528\n",
      "22656\n",
      "22784\n",
      "22912\n",
      "23040\n",
      "23168\n",
      "23296\n",
      "23424\n",
      "23552\n",
      "23680\n",
      "23808\n",
      "23936\n",
      "24064\n",
      "24192\n",
      "24320\n",
      "24448\n",
      "24576\n",
      "24704\n",
      "24832\n",
      "24960\n",
      "25088\n",
      "25216\n",
      "25344\n",
      "25472\n",
      "25600\n",
      "25728\n",
      "25856\n",
      "25984\n",
      "26112\n",
      "26240\n",
      "26368\n",
      "26496\n",
      "26624\n",
      "26752\n",
      "26880\n",
      "27008\n",
      "27136\n",
      "27264\n",
      "27392\n",
      "27520\n",
      "27648\n",
      "27776\n",
      "27904\n",
      "28032\n",
      "28160\n",
      "28288\n",
      "28416\n",
      "28544\n",
      "28672\n",
      "28800\n",
      "28928\n",
      "29056\n",
      "29184\n",
      "29312\n",
      "29440\n",
      "29568\n",
      "29696\n",
      "29824\n",
      "29952\n",
      "30080\n",
      "30208\n",
      "30336\n",
      "30464\n",
      "30592\n",
      "30720\n",
      "30848\n",
      "30976\n",
      "31104\n",
      "31232\n",
      "31360\n",
      "31488\n",
      "31616\n",
      "31744\n",
      "31872\n",
      "32000\n",
      "32128\n",
      "32256\n",
      "32384\n",
      "32512\n",
      "32640\n",
      "32768\n",
      "32896\n",
      "33024\n",
      "33152\n",
      "33280\n",
      "33408\n",
      "33536\n",
      "33664\n",
      "33792\n",
      "33920\n",
      "34048\n",
      "34176\n",
      "34304\n",
      "34432\n",
      "34560\n",
      "34688\n",
      "34816\n",
      "34944\n",
      "35072\n",
      "35200\n",
      "35328\n",
      "35456\n",
      "35584\n",
      "35712\n",
      "35840\n",
      "35968\n",
      "36096\n",
      "36224\n",
      "36352\n",
      "36480\n",
      "36608\n",
      "36736\n",
      "36864\n",
      "36992\n",
      "37120\n",
      "37248\n",
      "37376\n",
      "37504\n",
      "37632\n",
      "37760\n",
      "37888\n",
      "38016\n",
      "38144\n",
      "38272\n",
      "38400\n",
      "38528\n",
      "38656\n",
      "38784\n",
      "38912\n",
      "39040\n",
      "39168\n",
      "39296\n",
      "39424\n",
      "39552\n",
      "39680\n",
      "39808\n",
      "39936\n",
      "40064\n",
      "40192\n",
      "40320\n",
      "40448\n",
      "40576\n",
      "40704\n",
      "40832\n",
      "40960\n",
      "41088\n",
      "41216\n",
      "41344\n",
      "41472\n",
      "41600\n",
      "41728\n",
      "41856\n",
      "41984\n",
      "42112\n",
      "42240\n",
      "42368\n",
      "42496\n",
      "42624\n",
      "42752\n",
      "42880\n",
      "43008\n",
      "43136\n",
      "43264\n",
      "43392\n",
      "43520\n",
      "43648\n",
      "43776\n",
      "43904\n",
      "44032\n",
      "44160\n",
      "44288\n",
      "44416\n",
      "44544\n",
      "44672\n",
      "44800\n",
      "44928\n",
      "45056\n",
      "45184\n",
      "45312\n",
      "45440\n",
      "45568\n",
      "45696\n",
      "45824\n",
      "45952\n",
      "46080\n",
      "46208\n",
      "46336\n",
      "46464\n",
      "46592\n",
      "46720\n",
      "46848\n",
      "46976\n",
      "47104\n",
      "47232\n",
      "47360\n",
      "47488\n",
      "47616\n",
      "47744\n",
      "47872\n",
      "48000\n",
      "48128\n",
      "48256\n",
      "48384\n",
      "48512\n",
      "48640\n",
      "48768\n",
      "48896\n",
      "49024\n",
      "49152\n",
      "49280\n",
      "49408\n",
      "49536\n",
      "49664\n",
      "49792\n",
      "49920\n",
      "50048\n",
      "50176\n",
      "50304\n",
      "50432\n",
      "50560\n",
      "50688\n",
      "50816\n",
      "50944\n",
      "51072\n",
      "51200\n",
      "51328\n",
      "51456\n",
      "51584\n",
      "51712\n",
      "51840\n",
      "51968\n",
      "52096\n",
      "52224\n",
      "52352\n",
      "52480\n",
      "52608\n",
      "52736\n",
      "52864\n",
      "52992\n",
      "53120\n",
      "53248\n",
      "53376\n",
      "53504\n",
      "53632\n",
      "53760\n",
      "53888\n",
      "54016\n",
      "54144\n",
      "54272\n",
      "54400\n",
      "54528\n",
      "54656\n",
      "54784\n",
      "54912\n",
      "55040\n",
      "55168\n",
      "55296\n",
      "55424\n",
      "55552\n",
      "55680\n",
      "55808\n",
      "55936\n",
      "56064\n",
      "56192\n",
      "56320\n",
      "56448\n",
      "56576\n",
      "56704\n",
      "56832\n",
      "56960\n",
      "57088\n",
      "57216\n",
      "57344\n",
      "57472\n",
      "57600\n",
      "57728\n",
      "57856\n",
      "57984\n",
      "58112\n",
      "58240\n",
      "58368\n",
      "58496\n",
      "58624\n",
      "58752\n",
      "58880\n",
      "59008\n",
      "59136\n",
      "59264\n",
      "59392\n",
      "59520\n",
      "59648\n",
      "59776\n",
      "59904\n",
      "60032\n",
      "60160\n",
      "60288\n",
      "60416\n",
      "60544\n",
      "60672\n",
      "60800\n",
      "60928\n",
      "61056\n",
      "61184\n",
      "61312\n",
      "61440\n",
      "61568\n",
      "61696\n",
      "61824\n",
      "61952\n",
      "62080\n",
      "62208\n",
      "62336\n",
      "62464\n",
      "62592\n",
      "62720\n",
      "62848\n",
      "62976\n",
      "63104\n",
      "63232\n",
      "63360\n",
      "63488\n",
      "63616\n",
      "63744\n",
      "63872\n",
      "64000\n",
      "64128\n",
      "64256\n",
      "64384\n",
      "64512\n",
      "64640\n",
      "64768\n",
      "64896\n",
      "65024\n",
      "65152\n",
      "65280\n",
      "65408\n",
      "65536\n",
      "65664\n",
      "65792\n",
      "65920\n",
      "66048\n",
      "66176\n",
      "66304\n",
      "66432\n",
      "66560\n",
      "66688\n",
      "66816\n",
      "66944\n",
      "67072\n",
      "67200\n",
      "67328\n",
      "67456\n",
      "67584\n",
      "67712\n",
      "67840\n",
      "67968\n",
      "68096\n",
      "68224\n",
      "68352\n",
      "68480\n",
      "68608\n",
      "68736\n",
      "68864\n",
      "68992\n",
      "69120\n",
      "69248\n",
      "69376\n",
      "69504\n",
      "69632\n",
      "69760\n",
      "69888\n",
      "70016\n",
      "70144\n",
      "70272\n",
      "70400\n",
      "70528\n",
      "70656\n",
      "70784\n",
      "70912\n",
      "71040\n",
      "71168\n",
      "71296\n",
      "71424\n",
      "71552\n",
      "71680\n",
      "71808\n",
      "71936\n",
      "72064\n",
      "72192\n",
      "72320\n",
      "72448\n",
      "72576\n",
      "72704\n",
      "72832\n",
      "72960\n",
      "73088\n",
      "73216\n",
      "73344\n",
      "73472\n",
      "73600\n",
      "73728\n",
      "73856\n",
      "73984\n",
      "74112\n",
      "74240\n",
      "74368\n",
      "74496\n",
      "74624\n",
      "74752\n",
      "74880\n",
      "75008\n",
      "75136\n",
      "75264\n",
      "75392\n",
      "75520\n",
      "75648\n",
      "75776\n",
      "75904\n",
      "76032\n",
      "76160\n",
      "76288\n",
      "76416\n",
      "76544\n",
      "76672\n",
      "76800\n",
      "76928\n",
      "77056\n",
      "77184\n",
      "77312\n",
      "77440\n",
      "77568\n",
      "77696\n",
      "77824\n",
      "77952\n",
      "78080\n",
      "78208\n",
      "78336\n",
      "78464\n",
      "78592\n",
      "78720\n",
      "78848\n",
      "78976\n",
      "79104\n",
      "79232\n",
      "79360\n",
      "79488\n",
      "79616\n",
      "79744\n",
      "79872\n",
      "80000\n",
      "80128\n",
      "80256\n",
      "80384\n",
      "80512\n",
      "80640\n",
      "80768\n",
      "80896\n",
      "81024\n",
      "81152\n",
      "81280\n",
      "81408\n",
      "81536\n",
      "81664\n",
      "81792\n",
      "81920\n",
      "82048\n",
      "82176\n",
      "82304\n",
      "82432\n",
      "82560\n",
      "82688\n",
      "82816\n",
      "82944\n",
      "83072\n",
      "83200\n",
      "83328\n",
      "83456\n",
      "83584\n",
      "83712\n",
      "83840\n",
      "83968\n",
      "84096\n",
      "84224\n",
      "84352\n",
      "84480\n",
      "84608\n",
      "84736\n",
      "84864\n",
      "84992\n",
      "85120\n",
      "85248\n",
      "85376\n",
      "85504\n",
      "85632\n",
      "85760\n",
      "85888\n",
      "86016\n",
      "86144\n",
      "86272\n",
      "86400\n",
      "86528\n",
      "86656\n",
      "86784\n",
      "86912\n",
      "87040\n",
      "87168\n",
      "87296\n",
      "87424\n",
      "87552\n",
      "87680\n",
      "87808\n",
      "87936\n",
      "88064\n",
      "88192\n",
      "88320\n",
      "88448\n",
      "88576\n",
      "88704\n",
      "88832\n",
      "88960\n",
      "89088\n",
      "89216\n",
      "89344\n",
      "89472\n",
      "89600\n",
      "89728\n",
      "89856\n",
      "89984\n",
      "90112\n",
      "90240\n",
      "90368\n",
      "90496\n",
      "90624\n",
      "90752\n",
      "90880\n",
      "91008\n",
      "91136\n",
      "91264\n",
      "91392\n",
      "91520\n",
      "91648\n",
      "91776\n",
      "91904\n",
      "92032\n",
      "92160\n",
      "92288\n",
      "92416\n",
      "92544\n",
      "92672\n",
      "92800\n",
      "92928\n",
      "93056\n",
      "93184\n",
      "93312\n",
      "93440\n",
      "93568\n",
      "93696\n",
      "93824\n",
      "93952\n",
      "94080\n",
      "94208\n",
      "94336\n",
      "94464\n",
      "94592\n",
      "94720\n",
      "94848\n",
      "94976\n",
      "95104\n",
      "95232\n",
      "95360\n",
      "95488\n",
      "95616\n",
      "95744\n",
      "95872\n",
      "96000\n",
      "96128\n",
      "96256\n",
      "96384\n",
      "96512\n",
      "96640\n",
      "96768\n",
      "96896\n",
      "97024\n",
      "97152\n",
      "97280\n",
      "97408\n",
      "97536\n",
      "97664\n",
      "97792\n",
      "97920\n",
      "98048\n",
      "98176\n",
      "98304\n",
      "98432\n",
      "98560\n",
      "98688\n",
      "98816\n",
      "98944\n",
      "99072\n",
      "99200\n",
      "99328\n",
      "99456\n",
      "99584\n",
      "99712\n",
      "99840\n",
      "96\n",
      "224\n",
      "352\n",
      "480\n",
      "608\n",
      "736\n",
      "864\n",
      "992\n",
      "1120\n",
      "1248\n",
      "1376\n",
      "1504\n",
      "1632\n",
      "1760\n",
      "1888\n",
      "2016\n",
      "2144\n",
      "2272\n",
      "2400\n",
      "2528\n",
      "2656\n",
      "2784\n",
      "2912\n",
      "3040\n",
      "3168\n",
      "3296\n",
      "3424\n",
      "3552\n",
      "3680\n",
      "3808\n",
      "3936\n",
      "4064\n",
      "4192\n",
      "4320\n",
      "4448\n",
      "4576\n",
      "4704\n",
      "4832\n",
      "4960\n",
      "5088\n",
      "5216\n",
      "5344\n",
      "5472\n",
      "5600\n",
      "5728\n",
      "5856\n",
      "5984\n",
      "6112\n",
      "6240\n",
      "6368\n",
      "6496\n",
      "6624\n",
      "6752\n",
      "6880\n",
      "7008\n",
      "7136\n",
      "7264\n",
      "7392\n",
      "7520\n",
      "7648\n",
      "7776\n",
      "7904\n",
      "8032\n",
      "8160\n",
      "8288\n",
      "8416\n",
      "8544\n",
      "8672\n",
      "8800\n",
      "8928\n",
      "9056\n",
      "9184\n",
      "9312\n",
      "9440\n",
      "9568\n",
      "9696\n",
      "9824\n",
      "9952\n",
      "10080\n",
      "10208\n",
      "10336\n",
      "10464\n",
      "10592\n",
      "10720\n",
      "10848\n",
      "10976\n",
      "11104\n",
      "11232\n",
      "11360\n",
      "11488\n",
      "11616\n",
      "11744\n",
      "11872\n",
      "12000\n",
      "12128\n",
      "12256\n",
      "12384\n",
      "12512\n",
      "12640\n",
      "12768\n",
      "12896\n",
      "13024\n",
      "13152\n",
      "13280\n",
      "13408\n",
      "13536\n",
      "13664\n",
      "13792\n",
      "13920\n",
      "14048\n",
      "14176\n",
      "14304\n",
      "14432\n",
      "14560\n",
      "14688\n",
      "14816\n",
      "14944\n",
      "15072\n",
      "15200\n",
      "15328\n",
      "15456\n",
      "15584\n",
      "15712\n",
      "15840\n",
      "15968\n",
      "16096\n",
      "16224\n",
      "16352\n",
      "16480\n",
      "16608\n",
      "16736\n",
      "16864\n",
      "16992\n",
      "17120\n",
      "17248\n",
      "17376\n",
      "17504\n",
      "17632\n",
      "17760\n",
      "17888\n",
      "18016\n",
      "18144\n",
      "18272\n",
      "18400\n",
      "18528\n",
      "18656\n",
      "18784\n",
      "18912\n",
      "19040\n",
      "19168\n",
      "19296\n",
      "19424\n",
      "19552\n",
      "19680\n",
      "19808\n",
      "19936\n",
      "20064\n",
      "20192\n",
      "20320\n",
      "20448\n",
      "20576\n",
      "20704\n",
      "20832\n",
      "20960\n",
      "21088\n",
      "21216\n",
      "21344\n",
      "21472\n",
      "21600\n",
      "21728\n",
      "21856\n",
      "21984\n",
      "22112\n",
      "22240\n",
      "22368\n",
      "22496\n",
      "22624\n",
      "22752\n",
      "22880\n",
      "23008\n",
      "23136\n",
      "23264\n",
      "23392\n",
      "23520\n",
      "23648\n",
      "23776\n",
      "23904\n",
      "24032\n",
      "24160\n",
      "24288\n",
      "24416\n",
      "24544\n",
      "24672\n",
      "24800\n",
      "24928\n",
      "25056\n",
      "25184\n",
      "25312\n",
      "25440\n",
      "25568\n",
      "25696\n",
      "25824\n",
      "25952\n",
      "26080\n",
      "26208\n",
      "26336\n",
      "26464\n",
      "26592\n",
      "26720\n",
      "26848\n",
      "26976\n",
      "27104\n",
      "27232\n",
      "27360\n",
      "27488\n",
      "27616\n",
      "27744\n",
      "27872\n",
      "28000\n",
      "28128\n",
      "28256\n",
      "28384\n",
      "28512\n",
      "28640\n",
      "28768\n",
      "28896\n",
      "29024\n",
      "29152\n",
      "29280\n",
      "29408\n",
      "29536\n",
      "29664\n",
      "29792\n",
      "29920\n",
      "30048\n",
      "30176\n",
      "30304\n",
      "30432\n",
      "30560\n",
      "30688\n",
      "30816\n",
      "30944\n",
      "31072\n",
      "31200\n",
      "31328\n",
      "31456\n",
      "31584\n",
      "31712\n",
      "31840\n",
      "31968\n",
      "32096\n",
      "32224\n",
      "32352\n",
      "32480\n",
      "32608\n",
      "32736\n",
      "32864\n",
      "32992\n",
      "33120\n",
      "33248\n",
      "33376\n",
      "33504\n",
      "33632\n",
      "33760\n",
      "33888\n",
      "34016\n",
      "34144\n",
      "34272\n",
      "34400\n",
      "34528\n",
      "34656\n",
      "34784\n",
      "34912\n",
      "35040\n",
      "35168\n",
      "35296\n",
      "35424\n",
      "35552\n",
      "35680\n",
      "35808\n",
      "35936\n",
      "36064\n",
      "36192\n",
      "36320\n",
      "36448\n",
      "36576\n",
      "36704\n",
      "36832\n",
      "36960\n",
      "37088\n",
      "37216\n",
      "37344\n",
      "37472\n",
      "37600\n",
      "37728\n",
      "37856\n",
      "37984\n",
      "38112\n",
      "38240\n",
      "38368\n",
      "38496\n",
      "38624\n",
      "38752\n",
      "38880\n",
      "39008\n",
      "39136\n",
      "39264\n",
      "39392\n",
      "39520\n",
      "39648\n",
      "39776\n",
      "39904\n",
      "40032\n",
      "40160\n",
      "40288\n",
      "40416\n",
      "40544\n",
      "40672\n",
      "40800\n",
      "40928\n",
      "41056\n",
      "41184\n",
      "41312\n",
      "41440\n",
      "41568\n",
      "41696\n",
      "41824\n",
      "41952\n",
      "42080\n",
      "42208\n",
      "42336\n",
      "42464\n",
      "42592\n",
      "42720\n",
      "42848\n",
      "42976\n",
      "43104\n",
      "43232\n",
      "43360\n",
      "43488\n",
      "43616\n",
      "43744\n",
      "43872\n",
      "44000\n",
      "44128\n",
      "44256\n",
      "44384\n",
      "44512\n",
      "44640\n",
      "44768\n",
      "44896\n",
      "45024\n",
      "45152\n",
      "45280\n",
      "45408\n",
      "45536\n",
      "45664\n",
      "45792\n",
      "45920\n",
      "46048\n",
      "46176\n",
      "46304\n",
      "46432\n",
      "46560\n",
      "46688\n",
      "46816\n",
      "46944\n",
      "47072\n",
      "47200\n",
      "47328\n",
      "47456\n",
      "47584\n",
      "47712\n",
      "47840\n",
      "47968\n",
      "48096\n",
      "48224\n",
      "48352\n",
      "48480\n",
      "48608\n",
      "48736\n",
      "48864\n",
      "48992\n",
      "49120\n",
      "49248\n",
      "49376\n",
      "49504\n",
      "49632\n",
      "49760\n",
      "49888\n",
      "50016\n",
      "50144\n",
      "50272\n",
      "50400\n",
      "50528\n",
      "50656\n",
      "50784\n",
      "50912\n",
      "51040\n",
      "51168\n",
      "51296\n",
      "51424\n",
      "51552\n",
      "51680\n",
      "51808\n",
      "51936\n",
      "52064\n",
      "52192\n",
      "52320\n",
      "52448\n",
      "52576\n",
      "52704\n",
      "52832\n",
      "52960\n",
      "53088\n",
      "53216\n",
      "53344\n",
      "53472\n",
      "53600\n",
      "53728\n",
      "53856\n",
      "53984\n",
      "54112\n",
      "54240\n",
      "54368\n",
      "54496\n",
      "54624\n",
      "54752\n",
      "54880\n",
      "55008\n",
      "55136\n",
      "55264\n",
      "55392\n",
      "55520\n",
      "55648\n",
      "55776\n",
      "55904\n",
      "56032\n",
      "56160\n",
      "56288\n",
      "56416\n",
      "56544\n",
      "56672\n",
      "56800\n",
      "56928\n",
      "57056\n",
      "57184\n",
      "57312\n",
      "57440\n",
      "57568\n",
      "57696\n",
      "57824\n",
      "57952\n",
      "58080\n",
      "58208\n",
      "58336\n",
      "58464\n",
      "58592\n",
      "58720\n",
      "58848\n",
      "58976\n",
      "59104\n",
      "59232\n",
      "59360\n",
      "59488\n",
      "59616\n",
      "59744\n",
      "59872\n",
      "60000\n",
      "60128\n",
      "60256\n",
      "60384\n",
      "60512\n",
      "60640\n",
      "60768\n",
      "60896\n",
      "61024\n",
      "61152\n",
      "61280\n",
      "61408\n",
      "61536\n",
      "61664\n",
      "61792\n",
      "61920\n",
      "62048\n",
      "62176\n",
      "62304\n",
      "62432\n",
      "62560\n",
      "62688\n",
      "62816\n",
      "62944\n",
      "63072\n",
      "63200\n",
      "63328\n",
      "63456\n",
      "63584\n",
      "63712\n",
      "63840\n",
      "63968\n",
      "64096\n",
      "64224\n",
      "64352\n",
      "64480\n",
      "64608\n",
      "64736\n",
      "64864\n",
      "64992\n",
      "65120\n",
      "65248\n",
      "65376\n",
      "65504\n",
      "65632\n",
      "65760\n",
      "65888\n",
      "66016\n",
      "66144\n",
      "66272\n",
      "66400\n",
      "66528\n",
      "66656\n",
      "66784\n",
      "66912\n",
      "67040\n",
      "67168\n",
      "67296\n",
      "67424\n",
      "67552\n",
      "67680\n",
      "67808\n",
      "67936\n",
      "68064\n",
      "68192\n",
      "68320\n",
      "68448\n",
      "68576\n",
      "68704\n",
      "68832\n",
      "68960\n",
      "69088\n",
      "69216\n",
      "69344\n",
      "69472\n",
      "69600\n",
      "69728\n",
      "69856\n",
      "69984\n",
      "70112\n",
      "70240\n",
      "70368\n",
      "70496\n",
      "70624\n",
      "70752\n",
      "70880\n",
      "71008\n",
      "71136\n",
      "71264\n",
      "71392\n",
      "71520\n",
      "71648\n",
      "71776\n",
      "71904\n",
      "72032\n",
      "72160\n",
      "72288\n",
      "72416\n",
      "72544\n",
      "72672\n",
      "72800\n",
      "72928\n",
      "73056\n",
      "73184\n",
      "73312\n",
      "73440\n",
      "73568\n",
      "73696\n",
      "73824\n",
      "73952\n",
      "74080\n",
      "74208\n",
      "74336\n",
      "74464\n",
      "74592\n",
      "74720\n",
      "74848\n",
      "74976\n",
      "75104\n",
      "75232\n",
      "75360\n",
      "75488\n",
      "75616\n",
      "75744\n",
      "75872\n",
      "76000\n",
      "76128\n",
      "76256\n",
      "76384\n",
      "76512\n",
      "76640\n",
      "76768\n",
      "76896\n",
      "77024\n",
      "77152\n",
      "77280\n",
      "77408\n",
      "77536\n",
      "77664\n",
      "77792\n",
      "77920\n",
      "78048\n",
      "78176\n",
      "78304\n",
      "78432\n",
      "78560\n",
      "78688\n",
      "78816\n",
      "78944\n",
      "79072\n",
      "79200\n",
      "79328\n",
      "79456\n",
      "79584\n",
      "79712\n",
      "79840\n",
      "79968\n",
      "80096\n",
      "80224\n",
      "80352\n",
      "80480\n",
      "80608\n",
      "80736\n",
      "80864\n",
      "80992\n",
      "81120\n",
      "81248\n",
      "81376\n",
      "81504\n",
      "81632\n",
      "81760\n",
      "81888\n",
      "82016\n",
      "82144\n",
      "82272\n",
      "82400\n",
      "82528\n",
      "82656\n",
      "82784\n",
      "82912\n",
      "83040\n",
      "83168\n",
      "83296\n",
      "83424\n",
      "83552\n",
      "83680\n",
      "83808\n",
      "83936\n",
      "84064\n",
      "84192\n",
      "84320\n",
      "84448\n",
      "84576\n",
      "84704\n",
      "84832\n",
      "84960\n",
      "85088\n",
      "85216\n",
      "85344\n",
      "85472\n",
      "85600\n",
      "85728\n",
      "85856\n",
      "85984\n",
      "86112\n",
      "86240\n",
      "86368\n",
      "86496\n",
      "86624\n",
      "86752\n",
      "86880\n",
      "87008\n",
      "87136\n",
      "87264\n",
      "87392\n",
      "87520\n",
      "87648\n",
      "87776\n",
      "87904\n",
      "88032\n",
      "88160\n",
      "88288\n",
      "88416\n",
      "88544\n",
      "88672\n",
      "88800\n",
      "88928\n",
      "89056\n",
      "89184\n",
      "89312\n",
      "89440\n",
      "89568\n",
      "89696\n",
      "89824\n",
      "89952\n",
      "90080\n",
      "90208\n",
      "90336\n",
      "90464\n",
      "90592\n",
      "90720\n",
      "90848\n",
      "90976\n",
      "91104\n",
      "91232\n",
      "91360\n",
      "91488\n",
      "91616\n",
      "91744\n",
      "91872\n",
      "92000\n",
      "92128\n",
      "92256\n",
      "92384\n",
      "92512\n",
      "92640\n",
      "92768\n",
      "92896\n",
      "93024\n",
      "93152\n",
      "93280\n",
      "93408\n",
      "93536\n",
      "93664\n",
      "93792\n",
      "93920\n",
      "94048\n",
      "94176\n",
      "94304\n",
      "94432\n",
      "94560\n",
      "94688\n",
      "94816\n",
      "94944\n",
      "95072\n",
      "95200\n",
      "95328\n",
      "95456\n",
      "95584\n",
      "95712\n",
      "95840\n",
      "95968\n",
      "96096\n",
      "96224\n",
      "96352\n",
      "96480\n",
      "96608\n",
      "96736\n",
      "96864\n",
      "96992\n",
      "97120\n",
      "97248\n",
      "97376\n",
      "97504\n",
      "97632\n",
      "97760\n",
      "97888\n",
      "98016\n",
      "98144\n",
      "98272\n",
      "98400\n",
      "98528\n",
      "98656\n",
      "98784\n",
      "98912\n",
      "99040\n",
      "99168\n",
      "99296\n",
      "99424\n",
      "99552\n",
      "99680\n",
      "99808\n",
      "64\n",
      "192\n",
      "320\n",
      "448\n",
      "576\n",
      "704\n",
      "832\n",
      "960\n",
      "1088\n",
      "1216\n",
      "1344\n",
      "1472\n",
      "1600\n",
      "1728\n",
      "1856\n",
      "1984\n",
      "2112\n",
      "2240\n",
      "2368\n",
      "2496\n",
      "2624\n",
      "2752\n",
      "2880\n",
      "3008\n",
      "3136\n",
      "3264\n",
      "3392\n",
      "3520\n",
      "3648\n",
      "3776\n",
      "3904\n",
      "4032\n",
      "4160\n",
      "4288\n",
      "4416\n",
      "4544\n",
      "4672\n",
      "4800\n",
      "4928\n",
      "5056\n",
      "5184\n",
      "5312\n",
      "5440\n",
      "5568\n",
      "5696\n",
      "5824\n",
      "5952\n",
      "6080\n",
      "6208\n",
      "6336\n",
      "6464\n",
      "6592\n",
      "6720\n",
      "6848\n",
      "6976\n",
      "7104\n",
      "7232\n",
      "7360\n",
      "7488\n",
      "7616\n",
      "7744\n",
      "7872\n",
      "8000\n",
      "8128\n",
      "8256\n",
      "8384\n",
      "8512\n",
      "8640\n",
      "8768\n",
      "8896\n",
      "9024\n",
      "9152\n",
      "9280\n",
      "9408\n",
      "9536\n",
      "9664\n",
      "9792\n",
      "9920\n",
      "10048\n",
      "10176\n",
      "10304\n",
      "10432\n",
      "10560\n",
      "10688\n",
      "10816\n",
      "10944\n",
      "11072\n",
      "11200\n",
      "11328\n",
      "11456\n",
      "11584\n",
      "11712\n",
      "11840\n",
      "11968\n",
      "12096\n",
      "12224\n",
      "12352\n",
      "12480\n",
      "12608\n",
      "12736\n",
      "12864\n",
      "12992\n",
      "13120\n",
      "13248\n",
      "13376\n",
      "13504\n",
      "13632\n",
      "13760\n",
      "13888\n",
      "14016\n",
      "14144\n",
      "14272\n",
      "14400\n",
      "14528\n",
      "14656\n",
      "14784\n",
      "14912\n",
      "15040\n",
      "15168\n",
      "15296\n",
      "15424\n",
      "15552\n",
      "15680\n",
      "15808\n",
      "15936\n",
      "16064\n",
      "16192\n",
      "16320\n",
      "16448\n",
      "16576\n",
      "16704\n",
      "16832\n",
      "16960\n",
      "17088\n",
      "17216\n",
      "17344\n",
      "17472\n",
      "17600\n",
      "17728\n",
      "17856\n",
      "17984\n",
      "18112\n",
      "18240\n",
      "18368\n",
      "18496\n",
      "18624\n",
      "18752\n",
      "18880\n",
      "19008\n",
      "19136\n",
      "19264\n",
      "19392\n",
      "19520\n",
      "19648\n",
      "19776\n",
      "19904\n",
      "20032\n",
      "20160\n",
      "20288\n",
      "20416\n",
      "20544\n",
      "20672\n",
      "20800\n",
      "20928\n",
      "21056\n",
      "21184\n",
      "21312\n",
      "21440\n",
      "21568\n",
      "21696\n",
      "21824\n",
      "21952\n",
      "22080\n",
      "22208\n",
      "22336\n",
      "22464\n",
      "22592\n",
      "22720\n",
      "22848\n",
      "22976\n",
      "23104\n",
      "23232\n",
      "23360\n",
      "23488\n",
      "23616\n",
      "23744\n",
      "23872\n",
      "24000\n",
      "24128\n",
      "24256\n",
      "24384\n",
      "24512\n",
      "24640\n",
      "24768\n",
      "24896\n",
      "25024\n",
      "25152\n",
      "25280\n",
      "25408\n",
      "25536\n",
      "25664\n",
      "25792\n",
      "25920\n",
      "26048\n",
      "26176\n",
      "26304\n",
      "26432\n",
      "26560\n",
      "26688\n",
      "26816\n",
      "26944\n",
      "27072\n",
      "27200\n",
      "27328\n",
      "27456\n",
      "27584\n",
      "27712\n",
      "27840\n",
      "27968\n",
      "28096\n",
      "28224\n",
      "28352\n",
      "28480\n",
      "28608\n",
      "28736\n",
      "28864\n",
      "28992\n",
      "29120\n",
      "29248\n",
      "29376\n",
      "29504\n",
      "29632\n",
      "29760\n",
      "29888\n",
      "30016\n",
      "30144\n",
      "30272\n",
      "30400\n",
      "30528\n",
      "30656\n",
      "30784\n",
      "30912\n",
      "31040\n",
      "31168\n",
      "31296\n",
      "31424\n",
      "31552\n",
      "31680\n",
      "31808\n",
      "31936\n",
      "32064\n",
      "32192\n",
      "32320\n",
      "32448\n",
      "32576\n",
      "32704\n",
      "32832\n",
      "32960\n",
      "33088\n",
      "33216\n",
      "33344\n",
      "33472\n",
      "33600\n",
      "33728\n",
      "33856\n",
      "33984\n",
      "34112\n",
      "34240\n",
      "34368\n",
      "34496\n",
      "34624\n",
      "34752\n",
      "34880\n",
      "35008\n",
      "35136\n",
      "35264\n",
      "35392\n",
      "35520\n",
      "35648\n",
      "35776\n",
      "35904\n",
      "36032\n",
      "36160\n",
      "36288\n",
      "36416\n",
      "36544\n",
      "36672\n",
      "36800\n",
      "36928\n",
      "37056\n",
      "37184\n",
      "37312\n",
      "37440\n",
      "37568\n",
      "37696\n",
      "37824\n",
      "37952\n",
      "38080\n",
      "38208\n",
      "38336\n",
      "38464\n",
      "38592\n",
      "38720\n",
      "38848\n",
      "38976\n",
      "39104\n",
      "39232\n",
      "39360\n",
      "39488\n",
      "39616\n",
      "39744\n",
      "39872\n",
      "40000\n",
      "40128\n",
      "40256\n",
      "40384\n",
      "40512\n",
      "40640\n",
      "40768\n",
      "40896\n",
      "41024\n",
      "41152\n",
      "41280\n",
      "41408\n",
      "41536\n",
      "41664\n",
      "41792\n",
      "41920\n",
      "42048\n",
      "42176\n",
      "42304\n",
      "42432\n",
      "42560\n",
      "42688\n",
      "42816\n",
      "42944\n",
      "43072\n",
      "43200\n",
      "43328\n",
      "43456\n",
      "43584\n",
      "43712\n",
      "43840\n",
      "43968\n",
      "44096\n",
      "44224\n",
      "44352\n",
      "44480\n",
      "44608\n",
      "44736\n",
      "44864\n",
      "44992\n",
      "45120\n",
      "45248\n",
      "45376\n",
      "45504\n",
      "45632\n",
      "45760\n",
      "45888\n",
      "46016\n",
      "46144\n",
      "46272\n",
      "46400\n",
      "46528\n",
      "46656\n",
      "46784\n",
      "46912\n",
      "47040\n",
      "47168\n",
      "47296\n",
      "47424\n",
      "47552\n",
      "47680\n",
      "47808\n",
      "47936\n",
      "48064\n",
      "48192\n",
      "48320\n",
      "48448\n",
      "48576\n",
      "48704\n",
      "48832\n",
      "48960\n",
      "49088\n",
      "49216\n",
      "49344\n",
      "49472\n",
      "49600\n",
      "49728\n",
      "49856\n",
      "49984\n",
      "50112\n",
      "50240\n",
      "50368\n",
      "50496\n",
      "50624\n",
      "50752\n",
      "50880\n",
      "51008\n",
      "51136\n",
      "51264\n",
      "51392\n",
      "51520\n",
      "51648\n",
      "51776\n",
      "51904\n",
      "52032\n",
      "52160\n",
      "52288\n",
      "52416\n",
      "52544\n",
      "52672\n",
      "52800\n",
      "52928\n",
      "53056\n",
      "53184\n",
      "53312\n",
      "53440\n",
      "53568\n",
      "53696\n",
      "53824\n",
      "53952\n",
      "54080\n",
      "54208\n",
      "54336\n",
      "54464\n",
      "54592\n",
      "54720\n",
      "54848\n",
      "54976\n",
      "55104\n",
      "55232\n",
      "55360\n",
      "55488\n",
      "55616\n",
      "55744\n",
      "55872\n",
      "56000\n",
      "56128\n",
      "56256\n",
      "56384\n",
      "56512\n",
      "56640\n",
      "56768\n",
      "56896\n",
      "57024\n",
      "57152\n",
      "57280\n",
      "57408\n",
      "57536\n",
      "57664\n",
      "57792\n",
      "57920\n",
      "58048\n",
      "58176\n",
      "58304\n",
      "58432\n",
      "58560\n",
      "58688\n",
      "58816\n",
      "58944\n",
      "59072\n",
      "59200\n",
      "59328\n",
      "59456\n",
      "59584\n",
      "59712\n",
      "59840\n",
      "59968\n",
      "60096\n",
      "60224\n",
      "60352\n",
      "60480\n",
      "60608\n",
      "60736\n",
      "60864\n",
      "60992\n",
      "61120\n",
      "61248\n",
      "61376\n",
      "61504\n",
      "61632\n",
      "61760\n",
      "61888\n",
      "62016\n",
      "62144\n",
      "62272\n",
      "62400\n",
      "62528\n",
      "62656\n",
      "62784\n",
      "62912\n",
      "63040\n",
      "63168\n",
      "63296\n",
      "63424\n",
      "63552\n",
      "63680\n",
      "63808\n",
      "63936\n",
      "64064\n",
      "64192\n",
      "64320\n",
      "64448\n",
      "64576\n",
      "64704\n",
      "64832\n",
      "64960\n",
      "65088\n",
      "65216\n",
      "65344\n",
      "65472\n",
      "65600\n",
      "65728\n",
      "65856\n",
      "65984\n",
      "66112\n",
      "66240\n",
      "66368\n",
      "66496\n",
      "66624\n",
      "66752\n",
      "66880\n",
      "67008\n",
      "67136\n",
      "67264\n",
      "67392\n",
      "67520\n",
      "67648\n",
      "67776\n",
      "67904\n",
      "68032\n",
      "68160\n",
      "68288\n",
      "68416\n",
      "68544\n",
      "68672\n",
      "68800\n",
      "68928\n",
      "69056\n",
      "69184\n",
      "69312\n",
      "69440\n",
      "69568\n",
      "69696\n",
      "69824\n",
      "69952\n",
      "70080\n",
      "70208\n",
      "70336\n",
      "70464\n",
      "70592\n",
      "70720\n",
      "70848\n",
      "70976\n",
      "71104\n",
      "71232\n",
      "71360\n",
      "71488\n",
      "71616\n",
      "71744\n",
      "71872\n",
      "72000\n",
      "72128\n",
      "72256\n",
      "72384\n",
      "72512\n",
      "72640\n",
      "72768\n",
      "72896\n",
      "73024\n",
      "73152\n",
      "73280\n",
      "73408\n",
      "73536\n",
      "73664\n",
      "73792\n",
      "73920\n",
      "74048\n",
      "74176\n",
      "74304\n",
      "74432\n",
      "74560\n",
      "74688\n",
      "74816\n",
      "74944\n",
      "75072\n",
      "75200\n",
      "75328\n",
      "75456\n",
      "75584\n",
      "75712\n",
      "75840\n",
      "75968\n",
      "76096\n",
      "76224\n",
      "76352\n",
      "76480\n",
      "76608\n",
      "76736\n",
      "76864\n",
      "76992\n",
      "77120\n",
      "77248\n",
      "77376\n",
      "77504\n",
      "77632\n",
      "77760\n",
      "77888\n",
      "78016\n",
      "78144\n",
      "78272\n",
      "78400\n",
      "78528\n",
      "78656\n",
      "78784\n",
      "78912\n",
      "79040\n",
      "79168\n",
      "79296\n",
      "79424\n",
      "79552\n",
      "79680\n",
      "79808\n",
      "79936\n",
      "80064\n",
      "80192\n",
      "80320\n",
      "80448\n",
      "80576\n",
      "80704\n",
      "80832\n",
      "80960\n",
      "81088\n",
      "81216\n",
      "81344\n",
      "81472\n",
      "81600\n",
      "81728\n",
      "81856\n",
      "81984\n",
      "82112\n",
      "82240\n",
      "82368\n",
      "82496\n",
      "82624\n",
      "82752\n",
      "82880\n",
      "83008\n",
      "83136\n",
      "83264\n",
      "83392\n",
      "83520\n",
      "83648\n",
      "83776\n",
      "83904\n",
      "84032\n",
      "84160\n",
      "84288\n",
      "84416\n",
      "84544\n",
      "84672\n",
      "84800\n",
      "84928\n",
      "85056\n",
      "85184\n",
      "85312\n",
      "85440\n",
      "85568\n",
      "85696\n",
      "85824\n",
      "85952\n",
      "86080\n",
      "86208\n",
      "86336\n",
      "86464\n",
      "86592\n",
      "86720\n",
      "86848\n",
      "86976\n",
      "87104\n",
      "87232\n",
      "87360\n",
      "87488\n",
      "87616\n",
      "87744\n",
      "87872\n",
      "88000\n",
      "88128\n",
      "88256\n",
      "88384\n",
      "88512\n",
      "88640\n",
      "88768\n",
      "88896\n",
      "89024\n",
      "89152\n",
      "89280\n",
      "89408\n",
      "89536\n",
      "89664\n",
      "89792\n",
      "89920\n",
      "90048\n",
      "90176\n",
      "90304\n",
      "90432\n",
      "90560\n",
      "90688\n",
      "90816\n",
      "90944\n",
      "91072\n",
      "91200\n",
      "91328\n",
      "91456\n",
      "91584\n",
      "91712\n",
      "91840\n",
      "91968\n",
      "92096\n",
      "92224\n",
      "92352\n",
      "92480\n",
      "92608\n",
      "92736\n",
      "92864\n",
      "92992\n",
      "93120\n",
      "93248\n",
      "93376\n",
      "93504\n",
      "93632\n",
      "93760\n",
      "93888\n",
      "94016\n",
      "94144\n",
      "94272\n",
      "94400\n",
      "94528\n",
      "94656\n",
      "94784\n",
      "94912\n",
      "95040\n",
      "95168\n",
      "95296\n",
      "95424\n",
      "95552\n",
      "95680\n",
      "95808\n",
      "95936\n",
      "96064\n",
      "96192\n",
      "96320\n",
      "96448\n",
      "96576\n",
      "96704\n",
      "96832\n",
      "96960\n",
      "97088\n",
      "97216\n",
      "97344\n",
      "97472\n",
      "97600\n",
      "97728\n",
      "97856\n",
      "97984\n",
      "98112\n",
      "98240\n",
      "98368\n",
      "98496\n",
      "98624\n",
      "98752\n",
      "98880\n",
      "99008\n",
      "99136\n",
      "99264\n",
      "99392\n",
      "99520\n",
      "99648\n",
      "99776\n",
      "32\n",
      "160\n",
      "288\n",
      "416\n",
      "544\n",
      "672\n",
      "800\n",
      "928\n",
      "1056\n",
      "1184\n",
      "1312\n",
      "1440\n",
      "1568\n",
      "1696\n",
      "1824\n",
      "1952\n",
      "2080\n",
      "2208\n",
      "2336\n",
      "2464\n",
      "2592\n",
      "2720\n",
      "2848\n",
      "2976\n",
      "3104\n",
      "3232\n",
      "3360\n",
      "3488\n",
      "3616\n",
      "3744\n",
      "3872\n",
      "4000\n",
      "4128\n",
      "4256\n",
      "4384\n",
      "4512\n",
      "4640\n",
      "4768\n",
      "4896\n",
      "5024\n",
      "5152\n",
      "5280\n",
      "5408\n",
      "5536\n",
      "5664\n",
      "5792\n",
      "5920\n",
      "6048\n",
      "6176\n",
      "6304\n",
      "6432\n",
      "6560\n",
      "6688\n",
      "6816\n",
      "6944\n",
      "7072\n",
      "7200\n",
      "7328\n",
      "7456\n",
      "7584\n",
      "7712\n",
      "7840\n",
      "7968\n",
      "8096\n",
      "8224\n",
      "8352\n",
      "8480\n",
      "8608\n",
      "8736\n",
      "8864\n",
      "8992\n",
      "9120\n",
      "9248\n",
      "9376\n",
      "9504\n",
      "9632\n",
      "9760\n",
      "9888\n",
      "10016\n",
      "10144\n",
      "10272\n",
      "10400\n",
      "10528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10656\n",
      "10784\n",
      "10912\n",
      "11040\n",
      "11168\n",
      "11296\n",
      "11424\n",
      "11552\n",
      "11680\n",
      "11808\n",
      "11936\n",
      "12064\n",
      "12192\n",
      "12320\n",
      "12448\n",
      "12576\n",
      "12704\n",
      "12832\n",
      "12960\n",
      "13088\n",
      "13216\n",
      "13344\n",
      "13472\n",
      "13600\n",
      "13728\n",
      "13856\n",
      "13984\n",
      "14112\n",
      "14240\n",
      "14368\n",
      "14496\n",
      "14624\n",
      "14752\n",
      "14880\n",
      "15008\n",
      "15136\n",
      "15264\n",
      "15392\n",
      "15520\n",
      "15648\n",
      "15776\n",
      "15904\n",
      "16032\n",
      "16160\n",
      "16288\n",
      "16416\n",
      "16544\n",
      "16672\n",
      "16800\n",
      "16928\n",
      "17056\n",
      "17184\n",
      "17312\n",
      "17440\n",
      "17568\n",
      "17696\n",
      "17824\n",
      "17952\n",
      "18080\n",
      "18208\n",
      "18336\n",
      "18464\n",
      "18592\n",
      "18720\n",
      "18848\n",
      "18976\n",
      "19104\n",
      "19232\n",
      "19360\n",
      "19488\n",
      "19616\n",
      "19744\n",
      "19872\n",
      "20000\n",
      "20128\n",
      "20256\n",
      "20384\n",
      "20512\n",
      "20640\n",
      "20768\n",
      "20896\n",
      "21024\n",
      "21152\n",
      "21280\n",
      "21408\n",
      "21536\n",
      "21664\n",
      "21792\n",
      "21920\n",
      "22048\n",
      "22176\n",
      "22304\n",
      "22432\n",
      "22560\n",
      "22688\n",
      "22816\n",
      "22944\n",
      "23072\n",
      "23200\n",
      "23328\n",
      "23456\n",
      "23584\n",
      "23712\n",
      "23840\n",
      "23968\n",
      "24096\n",
      "24224\n",
      "24352\n",
      "24480\n",
      "24608\n",
      "24736\n",
      "24864\n",
      "24992\n",
      "25120\n",
      "25248\n",
      "25376\n",
      "25504\n",
      "25632\n",
      "25760\n",
      "25888\n",
      "26016\n",
      "26144\n",
      "26272\n",
      "26400\n",
      "26528\n",
      "26656\n",
      "26784\n",
      "26912\n",
      "27040\n",
      "27168\n",
      "27296\n",
      "27424\n",
      "27552\n",
      "27680\n",
      "27808\n",
      "27936\n",
      "28064\n",
      "28192\n",
      "28320\n",
      "28448\n",
      "28576\n",
      "28704\n",
      "28832\n",
      "28960\n",
      "29088\n",
      "29216\n",
      "29344\n",
      "29472\n",
      "29600\n",
      "29728\n",
      "29856\n",
      "29984\n",
      "30112\n",
      "30240\n",
      "30368\n",
      "30496\n",
      "30624\n",
      "30752\n",
      "30880\n",
      "31008\n",
      "31136\n",
      "31264\n",
      "31392\n",
      "31520\n",
      "31648\n",
      "31776\n",
      "31904\n",
      "32032\n",
      "32160\n",
      "32288\n",
      "32416\n",
      "32544\n",
      "32672\n",
      "32800\n",
      "32928\n",
      "33056\n",
      "33184\n",
      "33312\n",
      "33440\n",
      "33568\n",
      "33696\n",
      "33824\n",
      "33952\n",
      "34080\n",
      "34208\n",
      "34336\n",
      "34464\n",
      "34592\n",
      "34720\n",
      "34848\n",
      "34976\n",
      "35104\n",
      "35232\n",
      "35360\n",
      "35488\n",
      "35616\n",
      "35744\n",
      "35872\n",
      "36000\n",
      "36128\n",
      "36256\n",
      "36384\n",
      "36512\n",
      "36640\n",
      "36768\n",
      "36896\n",
      "37024\n",
      "37152\n",
      "37280\n",
      "37408\n",
      "37536\n",
      "37664\n",
      "37792\n",
      "37920\n",
      "38048\n",
      "38176\n",
      "38304\n",
      "38432\n",
      "38560\n",
      "38688\n",
      "38816\n",
      "38944\n",
      "39072\n",
      "39200\n",
      "39328\n",
      "39456\n",
      "39584\n",
      "39712\n",
      "39840\n",
      "39968\n",
      "40096\n",
      "40224\n",
      "40352\n",
      "40480\n",
      "40608\n",
      "40736\n",
      "40864\n",
      "40992\n",
      "41120\n",
      "41248\n",
      "41376\n",
      "41504\n",
      "41632\n",
      "41760\n",
      "41888\n",
      "42016\n",
      "42144\n",
      "42272\n",
      "42400\n",
      "42528\n",
      "42656\n",
      "42784\n",
      "42912\n",
      "43040\n",
      "43168\n",
      "43296\n",
      "43424\n",
      "43552\n",
      "43680\n",
      "43808\n",
      "43936\n",
      "44064\n",
      "44192\n",
      "44320\n",
      "44448\n",
      "44576\n",
      "44704\n",
      "44832\n",
      "44960\n",
      "45088\n",
      "45216\n",
      "45344\n",
      "45472\n",
      "45600\n",
      "45728\n",
      "45856\n",
      "45984\n",
      "46112\n",
      "46240\n",
      "46368\n",
      "46496\n",
      "46624\n",
      "46752\n",
      "46880\n",
      "47008\n",
      "47136\n",
      "47264\n",
      "47392\n",
      "47520\n",
      "47648\n",
      "47776\n",
      "47904\n",
      "48032\n",
      "48160\n",
      "48288\n",
      "48416\n",
      "48544\n",
      "48672\n",
      "48800\n",
      "48928\n",
      "49056\n",
      "49184\n",
      "49312\n",
      "49440\n",
      "49568\n",
      "49696\n",
      "49824\n",
      "49952\n",
      "50080\n",
      "50208\n",
      "50336\n",
      "50464\n",
      "50592\n",
      "50720\n",
      "50848\n",
      "50976\n",
      "51104\n",
      "51232\n",
      "51360\n",
      "51488\n",
      "51616\n",
      "51744\n",
      "51872\n",
      "52000\n",
      "52128\n",
      "52256\n",
      "52384\n",
      "52512\n",
      "52640\n",
      "52768\n",
      "52896\n",
      "53024\n",
      "53152\n",
      "53280\n",
      "53408\n",
      "53536\n",
      "53664\n",
      "53792\n",
      "53920\n",
      "54048\n",
      "54176\n",
      "54304\n",
      "54432\n",
      "54560\n",
      "54688\n",
      "54816\n",
      "54944\n",
      "55072\n",
      "55200\n",
      "55328\n",
      "55456\n",
      "55584\n",
      "55712\n",
      "55840\n",
      "55968\n",
      "56096\n",
      "56224\n",
      "56352\n",
      "56480\n",
      "56608\n",
      "56736\n",
      "56864\n",
      "56992\n",
      "57120\n",
      "57248\n",
      "57376\n",
      "57504\n",
      "57632\n",
      "57760\n",
      "57888\n",
      "58016\n",
      "58144\n",
      "58272\n",
      "58400\n",
      "58528\n",
      "58656\n",
      "58784\n",
      "58912\n",
      "59040\n",
      "59168\n",
      "59296\n",
      "59424\n",
      "59552\n",
      "59680\n",
      "59808\n",
      "59936\n",
      "60064\n",
      "60192\n",
      "60320\n",
      "60448\n",
      "60576\n",
      "60704\n",
      "60832\n",
      "60960\n",
      "61088\n",
      "61216\n",
      "61344\n",
      "61472\n",
      "61600\n",
      "61728\n",
      "61856\n",
      "61984\n",
      "62112\n",
      "62240\n",
      "62368\n",
      "62496\n",
      "62624\n",
      "62752\n",
      "62880\n",
      "63008\n",
      "63136\n",
      "63264\n",
      "63392\n",
      "63520\n",
      "63648\n",
      "63776\n",
      "63904\n",
      "64032\n",
      "64160\n",
      "64288\n",
      "64416\n",
      "64544\n",
      "64672\n",
      "64800\n",
      "64928\n",
      "65056\n",
      "65184\n",
      "65312\n",
      "65440\n",
      "65568\n",
      "65696\n",
      "65824\n",
      "65952\n",
      "66080\n",
      "66208\n",
      "66336\n",
      "66464\n",
      "66592\n",
      "66720\n",
      "66848\n",
      "66976\n",
      "67104\n",
      "67232\n",
      "67360\n",
      "67488\n",
      "67616\n",
      "67744\n",
      "67872\n",
      "68000\n",
      "68128\n",
      "68256\n",
      "68384\n",
      "68512\n",
      "68640\n",
      "68768\n",
      "68896\n",
      "69024\n",
      "69152\n",
      "69280\n",
      "69408\n",
      "69536\n",
      "69664\n",
      "69792\n",
      "69920\n",
      "70048\n",
      "70176\n",
      "70304\n",
      "70432\n",
      "70560\n",
      "70688\n",
      "70816\n",
      "70944\n",
      "71072\n",
      "71200\n",
      "71328\n",
      "71456\n",
      "71584\n",
      "71712\n",
      "71840\n",
      "71968\n",
      "72096\n",
      "72224\n",
      "72352\n",
      "72480\n",
      "72608\n",
      "72736\n",
      "72864\n",
      "72992\n",
      "73120\n",
      "73248\n",
      "73376\n",
      "73504\n",
      "73632\n",
      "73760\n",
      "73888\n",
      "74016\n",
      "74144\n",
      "74272\n",
      "74400\n",
      "74528\n",
      "74656\n",
      "74784\n",
      "74912\n",
      "75040\n",
      "75168\n",
      "75296\n",
      "75424\n",
      "75552\n",
      "75680\n",
      "75808\n",
      "75936\n",
      "76064\n",
      "76192\n",
      "76320\n",
      "76448\n",
      "76576\n",
      "76704\n",
      "76832\n",
      "76960\n",
      "77088\n",
      "77216\n",
      "77344\n",
      "77472\n",
      "77600\n",
      "77728\n",
      "77856\n",
      "77984\n",
      "78112\n",
      "78240\n",
      "78368\n",
      "78496\n",
      "78624\n",
      "78752\n",
      "78880\n",
      "79008\n",
      "79136\n",
      "79264\n",
      "79392\n",
      "79520\n",
      "79648\n",
      "79776\n",
      "79904\n",
      "80032\n",
      "80160\n",
      "80288\n",
      "80416\n",
      "80544\n",
      "80672\n",
      "80800\n",
      "80928\n",
      "81056\n",
      "81184\n",
      "81312\n",
      "81440\n",
      "81568\n",
      "81696\n",
      "81824\n",
      "81952\n",
      "82080\n",
      "82208\n",
      "82336\n",
      "82464\n",
      "82592\n",
      "82720\n",
      "82848\n",
      "82976\n",
      "83104\n",
      "83232\n",
      "83360\n",
      "83488\n",
      "83616\n",
      "83744\n",
      "83872\n",
      "84000\n",
      "84128\n",
      "84256\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3000\n",
    "for step in range(num_steps):\n",
    "    x = (step * 128) % (100000 - 128)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
